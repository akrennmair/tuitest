# = tuitest.rb - Text User Interface Testing Library
# 
# Copyright 2008 Andreas Krennmair mailto:ak@synflood.at
#
#
# == Introduction
#
# tuitest is a tool to create and run automated tests of text user interfaces.
# It is meant as a complement to the widespread use of unit tests, and uses
# concepts known from GUI testing tools with the difference that it applies
# them specifically to text- and terminal-based user interfaces.
#
# tuitest consists of two parts: first, the recorder, named tt-record. With
# the recorder, you start your application under test (AUT) in a fixed
# 80x25-sized virtual terminal, do the operations you want to have tested,
# and exit the application. tt-record will generate a script that replays
# your interaction with the application.
#
# The second part of tuitest is a Ruby module that provides helper functions
# and classes for the actual replay. The script generated by tt-record is
# a Ruby script that relies on this Ruby module. All you need to do in
# order to replay your interaction is to run the script with a Ruby
# interpreter.
#
# == Usage
# 
# You create a new script by running 
# 
#  tt-record scriptname.rb '<commandline>'
#
# Your AUT will then open, and you can simply start interacting with it,
# doing the operations that you want to have replayed later on. When you're
# finished, quit your AUT, and tt-record will exit. Your script is now ready.
#
# To replay the script, simply run
#
#  ruby scriptname.rb
#
# and you will again see the AUT window come up, your application start,
# and your AUT will be used in the same way and with exactly the same timing
# as you did. A snippet of such a script looks like this:
#
#  Tuitest.keypress("r"[0])
#  Tuitest.wait(1244)
#  
#  Tuitest.keypress(258)
#  Tuitest.wait(473)
#  
#  Tuitest.keypress("r"[0])
#  Tuitest.wait(3453)
#  
#  Tuitest.keypress(259)
#  Tuitest.wait(2215)
#  
#  Tuitest.keypress(10)
#  Tuitest.wait(5702)
#  
#  Tuitest.keypress("A"[0])
#  Tuitest.wait(980)
#
# == Adding Verifications
#
# To verify that your AUT behaves correctly, it is necessary to compare the
# AUT's actual output with some expected output. tuitest provides a Verifier
# class for this (every generated script already contains an instance of it).
# You can either add your verifications after script recording manually, or
# you can have the automatically generated during recording.
#
# The automatic generation of verifications works this way: at a certain
# point in time during execution, you take a snapshot of your AUT's current
# state, by pressing the F5 key. Subsequently pressing F5 will overwrite
# the previous snapshot. When you want to automatically generate verifications,
# press the F6 key. This will take another snapshot, but this time, all
# differences between the last snapshot taken with F5 and the current snapshot
# taken with F6 will be inserted as verifications into the script. This is
# especially useful when you press F5, then execute a certain action that
# leads to changes on the screen, and then press F6 to generate verifications
# for these changes. 
#
# After pressing F6, the snapshot used for verification generation will be the
# latest one.
#
# Here is an example of how an auto-generated verification looks like:
#
#  # begin auto-generated verification #1
#  verifier.expect(0, 65, "0 unread, 10 to")
#  verifier.expect(1, 5, " ")
#  verifier.expect(2, 5, " ")
#  verifier.expect(3, 5, " ")
#  verifier.expect(4, 5, " ")
#  # end auto-generated verification #1
#
# After having the script recorded, it is recommended to edit the script and
# to only use those verifications that are relevant to the test case.
#
# == Making Scripts Faster
#
# When running tests, one often doesn't want to have a very accurate timing,
# but wants to have the tests executed as quickly as possible. In order to 
# improve the speed of executions, the following "recipe" can be used:
# Remove all the Tuitest.wait calls from your script. Insert a
#  
#  Tuitest.wait_until_idle
#
# call right after the Tuitest.run call, and before every block of
# verifications. Tuitest.wait_until_idle stops execution until there is
# no screen change for more than 1 second. This is useful to give the
# AUT time to "catch up" with all the input that it gets.
#
# To automatically generate such scripts during recording, use tt-record with
# the -f parameter. This will generate fast scripts.
#
# == Integration with Test Management Tools
#
# If you want to integrate tuitest with test management tools, you can specify
# an (optional) XML file that contains the test run results. The format of this
# XML file is the same as produced by JUnit. These test run results can thus
# be used by your favorite test result reporting tool. The integration has been
# tested with the CI tool Hudson.


require 'tuitest.so'

module Tuitest

	# str = Tuitest.gettext(1, 3, 10)
	#
	# Returns 10 characters of text starting at 
	# row 1 (0-based), column 3 (0-based).
	def Tuitest.gettext(row, col, len)
		getrow(row)[col..col+len-1]
	end

	# Tuitest.wait_until_idle
	#
	# Waits until there is no screen change for more than
	# 1 second.
	def Tuitest.wait_until_idle
		state = newstate = nil
		begin
			state = take_snapshot
			wait(1000)
			newstate = take_snapshot
		end while states_are_different(state, newstate)
	end

	# Tuitest.wait_until_screen_contains_text
	#
	# Waits until the regular expression rx matches any of the
	# screen's lines. Optionally, a timeout (in milliseconds)
	# can be specified. A return value of true indicates that
	# the regular expression matched some text, while a return
	# value of false indicates that the function ran into the
	# specified timeout.
	def Tuitest.wait_until_screen_contains_text(rx, timeout = 0)
		no_timeout = (timeout == 0)
		begin
			return true if Tuitest.screen_contains_text(rx)
			wait(1000)
			timeout -= 1000 if timeout
		end while no_timeout or timeout > 0
		false
	end
	
	# Tuitest.screen_contains_text
	#
	# Returns true if the current screen contains a line that
	# matches the specified regular expression.
	def Tuitest.screen_contains_text(rx)
		take_snapshot.each do |line|
			return true if rx.matches(line)
		end
		false
	end

	# Tuitest.wait_until_expected_text
	#
	# Waits until the expected text appears on the specified
	# screen coordinates. Optionally, a timeout can be specified.
	# A return value of true indicates that
	# the the expected text was found, while a return
	# value of false indicates that the function ran into the
	# specified timeout.
	def Tuitest.wait_until_expected_text(row, col, expected_text, timeout = 0)
		no_timeout = (timeout == 0)
		begin
			return true if Tuitest.gettext(row, col, expected_text.length) == expected_text
			wait(1000)
			timeout -= 1000 if timeout
		end while no_timeout or timeout > 0
		false
	end


	class Verifier

		def initialize(logfile = nil, xmlfile = nil)
			@verifications = [ ]
			@logfile = logfile
			@xmlfile = xmlfile
			@errcount = 0
			@warncount = 0
		end

		def log_fail(errmsg, failmethod = :hard)
			case failmethod
			when :hard
				@verifications << [ :error, errmsg ]
				@errcount += 1
				Tuitest.close
				finish
				Kernel.exit(1)
			when :soft
				@verifications << [ :warn, errmsg ]
				@warncount += 1
			end
		end

		# Verifies whether the expected text is on the expected coordinate.
		# If failmethod equals :hard, then the execution will stop, and an
		# error will be logged. If failmethod equals :soft, the execution
		# continues and a warning will be logged.
		def expect(row, col, expected_text, failmethod = :hard)
			found_text = Tuitest.gettext(row, col, expected_text.length)
			if found_text != expected_text then
				log_fail("On (#{row},#{col}), expected `#{expected_text}', but found `#{found_text}'", failmethod)
			else
				@verifications << [ :ok, "On (#{row},#{col}), found `#{found_text}' as expected." ]
			end
		end

		# Writes the verification results to the logfile and prints out a status message.
		# If there were warnings or errors, the complete log is printed to stdout.
		def finish
			write_log_to_file(@logfile)
			write_xmlfile(@xmlfile)
			if @errcount > 0 or @warncount > 0 then
				write_log_to_stdout
			end
			puts "Test run finished (#{@errcount} errors, #{@warncount} warnings)."
		end

		private

		def write_log_to_stdout
			write_log_to_stream($stdout)
		end

		def write_log_to_file(file)
			File.open(file,"w+") { |f| write_log_to_stream(f) }
		end

		def write_xmlfile(file)
			return if not file
			File.open(file, "w+") do |f|
				f << "<testsuite name='#{$0}' failures='#{@errcount}' errors='#{@warncount}' tests='#{@verifications.size}'>\n"
				@verifications.each_index do |i|
					f << "<testcase name='#{$0}.verification#{i+1}' time='0.0' classname='#{$0}.verification#{i+1}'>"
					if @verifications[i][0] == :error then
						f << "<failure><![CDATA[#{@verifications[i][1]}]]></failure>"
					elsif @verifications[i][1] == :warn then
						f << "<error><![CDATA[#{@verifications[i][1]}]]></error>"
					end
					f << "</testcase>\n"
				end
				f << "</testsuite>\n"
			end
		end

		def write_log_to_stream(stream)
			@verifications.each do |v|
				level = v[0]
				text = v[1]
				case level
				when :ok
					stream.puts("I: #{text}")
				when :warn
					stream.puts("W: #{text}")
				when :error
					stream.puts("E: #{text}")
				end
			end
		end

	end

	private

	def Tuitest.take_snapshot
		rows = [ ]
		0.upto(24) do |i|
			rows << getrow(i)
		end
		rows
	end

	def Tuitest.states_are_different(oldstate, newstate)
		0.upto(24) do |i|
			if oldstate[i] != newstate[i] then
				return true
			end
		end
		false
	end

end
